## Shannon Entropy
----
# property
- the amount of information of event X depends on it's probability $P_x$.
- Continuity: $I(p)$ is a continuous function of $P$.
- Addtivity: $I(p_x, p_y)$ = $I(p_x) + I(p_y)$ for independent events X
and Y.
