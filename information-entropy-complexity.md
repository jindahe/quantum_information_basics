# Shannon Entropy
----
## property
- the amount of information of event X depends on it's probability $P_x$.
- Continuity: $I(p)$ is a continuous function of $p$.
- Additivity: $I(p_x, p_y)$ = $I(p_x) + I(p_y)$ for independent events X
and Y.

Due to the additivity, for any rational r = s/t, 
$$
I(p_x^r)=rI(p_x)
$$

